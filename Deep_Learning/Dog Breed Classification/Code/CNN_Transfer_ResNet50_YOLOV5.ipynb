{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SKx6KBezEbPs"
      },
      "source": [
        "# Convolutional Neural Networks\n",
        "\n",
        "## Dog breed classification using transfer learning\n",
        "\n",
        "\n",
        "\n",
        "## Step 1: import dataset\n",
        "\n",
        "Make sure that you've downloaded the required dog dataset:\n",
        "* Download the dataset, unzip the folder and place it in this project's home directory, at the location `/dogs`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u7UuDfPHEbPt",
        "outputId": "d6c9cf32-e8c4-49a1-f02d-3566dbc66836"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "There are 8351 total dog images.\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from glob import glob\n",
        "\n",
        "# load filenames\n",
        "dog_files = np.array(glob(\"dogs/*/*/*\"))\n",
        "\n",
        "# print the number of images in the dataset\n",
        "print('There are %d total dog images.' % len(dog_files))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "89VVDc1xEbPv"
      },
      "source": [
        "## Step 2: detect dogs\n",
        "\n",
        "In this section, we will use a Pre-trained resnet50 Model to detect dogs.\n",
        "\n",
        "The following code cell downloads the resnet50 model, along with weights that have been trained on [ImageNet](http://www.image-net.org/), a large, popular dataset used for image classification with 1000 categories."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K5Bzgi6gEbPv",
        "outputId": "09ff1bf8-89ea-4ca1-9ef9-cfe3c10a76d1"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision.models as models\n",
        "\n",
        "# define resnet50 model\n",
        "resnet50 = models.resnet50(pretrained=True)\n",
        "\n",
        "# check if CUDA is available and move model to GPU\n",
        "use_cuda = torch.cuda.is_available()\n",
        "if use_cuda:\n",
        "    resnet50 = resnet50.cuda()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5DMxb1WsEbPv"
      },
      "source": [
        "### Using the pre-trained model\n",
        "\n",
        "Next, we will write a function that accepts as input a path to an image, and returns an integer between 0 and 999 (inclusive), representing one of the 1000 possible classes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "_o2ZO9bmEbPw"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# Set PIL to be tolerant of image files that are truncated.\n",
        "from PIL import ImageFile\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
        "\n",
        "def resnet50_predict(img_path):\n",
        "    '''\n",
        "    Use pre-trained resnet50 model to obtain index corresponding to\n",
        "    predicted class for image at specified path\n",
        "\n",
        "    Args:\n",
        "        img_path: path to an image\n",
        "\n",
        "    Returns:\n",
        "        Index corresponding to resnet50 model's prediction\n",
        "    '''\n",
        "\n",
        "    image = Image.open(img_path).convert('RGB')\n",
        "    normalize = transforms.Compose([\n",
        "            transforms.Resize(224),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.25, 0.25, 0.25])])\n",
        "\n",
        "    image = normalize(image)[:3,:,:].unsqueeze(0)\n",
        "\n",
        "    if use_cuda:\n",
        "        image = image.cuda()\n",
        "\n",
        "    classify=resnet50(image)\n",
        "\n",
        "    index = classify.argmax().item() #index of the class with highest proba returned as scalar\n",
        "\n",
        "    return index # predicted class index"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LYpGsU7kEbPw"
      },
      "source": [
        "Among output classes, categories corresponding to dogs appear in an uninterrupted sequence and correspond to dictionary keys 151-268 (inclusive).  Therefore, to verify whether a dog is detected, we only need to check if the pre-trained model predicts an index between 151 and 268.\n",
        "\n",
        "The `dog_detector` function below returns `True` if a dog is detected in an image, and `False` if not."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "IwaDaizzEbPw"
      },
      "outputs": [],
      "source": [
        "def dog_detector(img_path):\n",
        "    res_ = resnet50_predict(img_path)\n",
        "    if  (res_ >= 151 and res_ <= 268):\n",
        "        return True\n",
        "    else:\n",
        "        return False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lhACyTpCEbPw"
      },
      "source": [
        "### Test your dog detector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u1rXXhCDEbPw",
        "outputId": "56e36fcd-c839-46cf-d583-e304f5ec89cd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dogs detected: 0 %\n"
          ]
        }
      ],
      "source": [
        "# Test the performance of the dog_detector function\n",
        "# on the first 100 images.\n",
        "\n",
        "dog_files_short = dog_files[:100]\n",
        "count_dog_dog = sum(dog_detector(img) for img in dog_files_short)\n",
        "print('Dogs detected: {} %'.format(count_dog_dog))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ALHDTjHGEbPx"
      },
      "source": [
        "## Step 3: create a CNN to classify dog breeds using transfer learning\n",
        "### Specify data loaders\n",
        "\n",
        "In the following code cell, we write three separate [data loaders](http://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader) for the training, validation, and test datasets (located at `dogs/train`, `dogs/valid`, and `dogs/test`, respectively).  You may find [this documentation on custom datasets](http://pytorch.org/docs/stable/torchvision/datasets.html) to be a useful resource.  If you are interested in augmenting your training and/or validation data, check out the wide variety of [transforms](http://pytorch.org/docs/stable/torchvision/transforms.html?highlight=transform)!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "6SXW81PcEbPx"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from torchvision import datasets\n",
        "\n",
        "# Writing data loaders for training, validation, and test sets\n",
        "# Specifying appropriate transforms, and batch_sizes\n",
        "batch_size  = 20\n",
        "num_workers = 0\n",
        "\n",
        "img_transform = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.RandomResizedCrop(224),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "train_data=datasets.ImageFolder('dogs/train', transform = img_transform)\n",
        "validation_data=datasets.ImageFolder('dogs/valid', transform = img_transform)\n",
        "test_data=datasets.ImageFolder('dogs/test', transform = img_transform)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, num_workers=num_workers, shuffle=True)\n",
        "valid_loader = torch.utils.data.DataLoader(validation_data, batch_size=batch_size, num_workers=num_workers, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, num_workers=num_workers)\n",
        "\n",
        "loaders_transfer = {\n",
        "    'train': train_loader,\n",
        "    'valid': valid_loader,\n",
        "    'test': test_loader\n",
        "}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c5KpDLxMEbPx"
      },
      "source": [
        "### Model architecture\n",
        "\n",
        "Transfer learning is used to create a CNN to classify dog breed.  The initialized model will be saved as the variable `model_transfer`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hK5yKQT2EbPx",
        "outputId": "b70e4141-9abc-43c2-e663-dc61c0c3964e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ResNet(\n",
            "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU(inplace=True)\n",
            "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  (layer1): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (3): Bottleneck(\n",
            "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (layer3): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (3): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (4): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (5): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (layer4): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "import torchvision.models as models\n",
        "import torch.nn as nn\n",
        "\n",
        "# model architecture\n",
        "model_transfer = models.resnet50(pretrained=True)\n",
        "print(model_transfer)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LjjV5ZCjEbPx"
      },
      "source": [
        "Since resnet50 isn't functional like VGG16, it does not have a classifier and will use it's own functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "EH38kVvwEbPx"
      },
      "outputs": [],
      "source": [
        "model_transfer = models.resnet50(pretrained=True)\n",
        "for param in model_transfer.parameters():\n",
        "    param.requires_grad = False\n",
        "model_transfer.fc = nn.Linear(model_transfer.fc.in_features, 133)\n",
        "if use_cuda:\n",
        "    model_transfer = model_transfer.cuda()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_a0VYsGQEbPy"
      },
      "source": [
        "### Specify loss function and optimizer\n",
        "\n",
        "The following code cell is used to specify a [loss function](http://pytorch.org/docs/master/nn.html#loss-functions) and an [optimizer](http://pytorch.org/docs/master/optim.html).  The chosen loss function is saved as `criterion_transfer`, and the optimizer as `optimizer_transfer`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "uYtPE75iEbPy"
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "criterion_transfer = torch.nn.CrossEntropyLoss()\n",
        "optimizer_transfer = optim.SGD(model_transfer.fc.parameters(), lr=0.01)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sCisvyDlEbPy"
      },
      "source": [
        "### Train and validate the model\n",
        "\n",
        "Now we will train and validate our model, and we will save the model parameters as save_path `'model_transfer.pt'`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "lf0wHEUhEbPy",
        "outputId": "f1715c24-eea2-410d-8cd4-af26cb644274"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 1 \tTraining Loss: 2.950188 \tValidation Loss: 2.399353\n",
            "Validation loss decreased (inf --> 2.399353).  Saving model ...\n",
            "Epoch: 2 \tTraining Loss: 2.355038 \tValidation Loss: 1.946906\n",
            "Validation loss decreased (2.399353 --> 1.946906).  Saving model ...\n",
            "Epoch: 3 \tTraining Loss: 1.987067 \tValidation Loss: 1.686647\n",
            "Validation loss decreased (1.946906 --> 1.686647).  Saving model ...\n",
            "Epoch: 4 \tTraining Loss: 1.792759 \tValidation Loss: 1.507887\n",
            "Validation loss decreased (1.686647 --> 1.507887).  Saving model ...\n",
            "Epoch: 5 \tTraining Loss: 1.649313 \tValidation Loss: 1.416335\n",
            "Validation loss decreased (1.507887 --> 1.416335).  Saving model ...\n",
            "Epoch: 6 \tTraining Loss: 1.521599 \tValidation Loss: 1.396135\n",
            "Validation loss decreased (1.416335 --> 1.396135).  Saving model ...\n",
            "Epoch: 7 \tTraining Loss: 1.451331 \tValidation Loss: 1.298116\n",
            "Validation loss decreased (1.396135 --> 1.298116).  Saving model ...\n",
            "Epoch: 8 \tTraining Loss: 1.422777 \tValidation Loss: 1.326404\n",
            "Epoch: 9 \tTraining Loss: 1.324414 \tValidation Loss: 1.305559\n",
            "Epoch: 10 \tTraining Loss: 1.267925 \tValidation Loss: 1.165111\n",
            "Validation loss decreased (1.298116 --> 1.165111).  Saving model ...\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# @title Default title text\n",
        "from PIL import ImageFile\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
        "\n",
        "def train(n_epochs, loaders, model, optimizer, criterion, use_cuda, save_path):\n",
        "    \"\"\"returns trained model\"\"\"\n",
        "    # initialize tracker for minimum validation loss\n",
        "    valid_loss_min = np.Inf\n",
        "\n",
        "    for epoch in range(1, n_epochs+1):\n",
        "        # initialize variables to monitor training and validation loss\n",
        "        train_loss = 0.0\n",
        "        valid_loss = 0.0\n",
        "\n",
        "        ###################\n",
        "        # train the model #\n",
        "        ###################\n",
        "        model.train()\n",
        "        for batch_idx, (data, target) in enumerate(loaders['train']):\n",
        "            # move to GPU\n",
        "            if use_cuda:\n",
        "                data, target = data.cuda(), target.cuda()\n",
        "            # find the loss and update the model parameters accordingly\n",
        "            # record the average training loss\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            output = model(data)\n",
        "            loss = criterion(output, target)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_loss = train_loss + ((1 / (batch_idx + 1)) * (loss.item() - train_loss))\n",
        "\n",
        "        ######################\n",
        "        # validate the model #\n",
        "        ######################\n",
        "        model.eval()\n",
        "        for batch_idx, (data, target) in enumerate(loaders['valid']):\n",
        "            # move to GPU\n",
        "            if use_cuda:\n",
        "                data, target = data.cuda(), target.cuda()\n",
        "            ## update the average validation loss\n",
        "            output = model(data)\n",
        "            loss = criterion(output, target)\n",
        "            valid_loss = valid_loss + ((1 / (batch_idx + 1)) * (loss.item() - valid_loss))\n",
        "\n",
        "\n",
        "        # print training/validation statistics\n",
        "        print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n",
        "            epoch,\n",
        "            train_loss,\n",
        "            valid_loss\n",
        "            ))\n",
        "\n",
        "        # save the model if validation loss has decreased\n",
        "        if valid_loss <= valid_loss_min:\n",
        "            print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
        "            valid_loss_min,\n",
        "            valid_loss))\n",
        "            torch.save(model.state_dict(), save_path)\n",
        "            valid_loss_min = valid_loss\n",
        "    # return trained model\n",
        "    return model\n",
        "\n",
        "\n",
        "# train the model\n",
        "n_epochs = 10\n",
        "model_transfer = train(n_epochs, loaders_transfer, model_transfer, optimizer_transfer, criterion_transfer, use_cuda, 'model_transfer.pt')\n",
        "\n",
        "# load the model that got the best validation accuracy (uncomment the line below)\n",
        "model_transfer.load_state_dict(torch.load('model_transfer.pt'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tnUysLUrEbPy"
      },
      "source": [
        "### Test the model\n",
        "\n",
        "Let's try out our model on the test dataset. We will calculate and print the test loss and accuracy.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "2q4ZYkcnEbPy"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Loss: 4.949788\n",
            "\n",
            "\n",
            "Test Accuracy:  0% ( 6/836)\n"
          ]
        }
      ],
      "source": [
        "def test(loaders, model, criterion, use_cuda):\n",
        "\n",
        "    # monitor test loss and accuracy\n",
        "    test_loss = 0.\n",
        "    correct = 0.\n",
        "    total = 0.\n",
        "\n",
        "    model.eval()\n",
        "    for batch_idx, (data, target) in enumerate(loaders['test']):\n",
        "        # move to GPU\n",
        "        if use_cuda:\n",
        "            data, target = data.cuda(), target.cuda()\n",
        "        # forward pass: compute predicted outputs by passing inputs to the model\n",
        "        output = model(data)\n",
        "        # calculate the loss\n",
        "        loss = criterion(output, target)\n",
        "        # update average test loss\n",
        "        test_loss = test_loss + ((1 / (batch_idx + 1)) * (loss.data - test_loss))\n",
        "        # convert output probabilities to predicted class\n",
        "        pred = output.data.max(1, keepdim=True)[1]\n",
        "        # compare predictions to true label\n",
        "        correct += np.sum(np.squeeze(pred.eq(target.data.view_as(pred))).cpu().numpy())\n",
        "        total += data.size(0)\n",
        "\n",
        "    print('Test Loss: {:.6f}\\n'.format(test_loss))\n",
        "\n",
        "    print('\\nTest Accuracy: %2d%% (%2d/%2d)' % (\n",
        "        100. * correct / total, correct, total))\n",
        "\n",
        "test(loaders_transfer, model_transfer, criterion_transfer, use_cuda)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i4kVj9P9EbPy"
      },
      "source": [
        "### Predict dog breed with the model\n",
        "\n",
        "Let's write a function that takes an image path as input and returns the dog breed that is predicted by our model.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "hosHgH6SEbPz"
      },
      "outputs": [],
      "source": [
        "# list of class names by index, i.e. a name can be accessed like class_names[0]\n",
        "class_names = [item[4:].replace(\"_\", \" \") for item in loaders_transfer['train'].dataset.classes]\n",
        "\n",
        "def predict_breed_transfer(img_path):\n",
        "    # load the image and return the predicted breed\n",
        "    image = Image.open(img_path).convert('RGB')\n",
        "    normalize = transforms.Compose([\n",
        "            transforms.Resize(224),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.25, 0.25, 0.25])])\n",
        "\n",
        "    image = normalize(image)[:3,:,:].unsqueeze(0)\n",
        "\n",
        "    if use_cuda:\n",
        "        image = image.cuda()\n",
        "\n",
        "    classify=model_transfer(image)\n",
        "    index = classify.argmax().item() #index of the class with highest proba returned as scalar\n",
        "\n",
        "\n",
        "    return class_names[index]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bz89LfpmEbPz"
      },
      "source": [
        "Now let us try with our own images. Create a folder named myImages and put inside some dog images that you obtain\n",
        "from the internet (or from your smartphone camera if you own one or more dogs...)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "2hhmBQ9REbPz"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "This dog breed is likely a  Dachshund\n",
            "This dog breed is likely a  Lowchen\n",
            "This dog breed is likely a  Keeshond\n",
            "This dog breed is likely a  Clumber spaniel\n",
            "This dog breed is likely a  Lowchen\n",
            "This dog breed is likely a  Clumber spaniel\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "imgsFolder='myImages/'\n",
        "for imgFile in os.listdir(imgsFolder):\n",
        "    img_path=os.path.join(imgsFolder,imgFile)\n",
        "    img = cv2.imread(img_path)\n",
        "    plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
        "    plt.show()\n",
        "    print(\"This dog breed is likely a \", predict_breed_transfer(img_path))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using cache found in C:\\Users\\m_a_g/.cache\\torch\\hub\\ultralytics_yolov5_master\n",
            "YOLOv5  2024-4-1 Python-3.11.0 torch-2.2.1+cpu CPU\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients, 16.4 GFLOPs\n",
            "Adding AutoShape... \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dog 1 breed: Border collie\n",
            "Dog 1 breed: Japanese chin\n",
            "Dog 2 breed: American foxhound\n",
            "Dog 3 breed: Australian cattle dog\n",
            "Dog 4 breed: Australian cattle dog\n",
            "Dog 5 breed: Australian cattle dog\n",
            "Dog 6 breed: Pekingese\n",
            "Dog 1 breed: Norwegian lundehund\n",
            "No dogs detected in the image.\n",
            "Dog 1 breed: Labrador retriever\n",
            "Dog 1 breed: Pointer\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from glob import glob\n",
        "from PIL import Image\n",
        "import os\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# Load YOLOv5 model\n",
        "model = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True)\n",
        "\n",
        "# Set device to GPU if available\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "model.to(device)\n",
        "\n",
        "# Define function to detect dogs using YOLOv5\n",
        "def detect_dogs_yolov5(img_path):\n",
        "    \"\"\"\n",
        "    Detects dogs using YOLOv5, predicts breeds using a transfer learning model,\n",
        "    and visualizes the results.\n",
        "\n",
        "    Args:\n",
        "        img_path (str): Path to the image file.\n",
        "\n",
        "    Returns:\n",
        "        list: List of predicted dog breeds for each detected dog (or None if no dogs detected).\n",
        "        ndarray: Annotated image with bounding boxes drawn around detected dogs.\n",
        "    \"\"\"\n",
        "\n",
        "    # Perform inference\n",
        "    results = model(img_path)\n",
        "\n",
        "    # Get labels and coordinates of detected objects\n",
        "    labels = results.names\n",
        "    boxes = results.xyxy[0].cpu().numpy()\n",
        "\n",
        "    # Filter out only \"dog\" class detections\n",
        "    dog_boxes = [box for box in boxes if labels[int(box[-1])] == 'dog']\n",
        "\n",
        "    # If no dogs detected, return None\n",
        "    if len(dog_boxes) == 0:\n",
        "        return None, None\n",
        "\n",
        "    # Load the image\n",
        "    if isinstance(img_path, str):\n",
        "        img = cv2.imread(img_path)\n",
        "    else:\n",
        "        img = img_path\n",
        "\n",
        "    # Initialize list to store detected dog breeds\n",
        "    dog_breeds = []\n",
        "\n",
        "    # Process each detected dog\n",
        "    for box in dog_boxes:\n",
        "        # Extract coordinates of the detected dog\n",
        "        x1, y1, x2, y2, conf, _ = box.astype(int)\n",
        "\n",
        "        # Crop the image to contain only the detected dog\n",
        "        dog_img = img[y1:y2, x1:x2]\n",
        "\n",
        "        # Resize the image to 224x224 (required input size for resnet50)\n",
        "        transform = transforms.Compose([\n",
        "            transforms.ToPILImage(),\n",
        "            transforms.Resize((224, 224)),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.25, 0.25, 0.25])\n",
        "        ])\n",
        "        dog_img = transform(dog_img).unsqueeze(0).to(device)\n",
        "\n",
        "        # Predict the breed of the dog using the transfer learning model\n",
        "        breed_index = model_transfer(dog_img).argmax().item()\n",
        "        breed = class_names[breed_index]\n",
        "\n",
        "        # Append the predicted breed to the list\n",
        "        dog_breeds.append(breed)\n",
        "\n",
        "        # Draw a bounding box around the detected dog (optional)\n",
        "        cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
        "\n",
        "    # Return the list of dog breeds and annotated image\n",
        "    return dog_breeds, img\n",
        "\n",
        "# Test the dog detection and breed prediction function\n",
        "imgsFolder = 'myImages/'\n",
        "for imgFile in os.listdir(imgsFolder):\n",
        "    img_path = os.path.join(imgsFolder, imgFile)\n",
        "\n",
        "    # Detect dogs and predict breeds\n",
        "    dog_breeds, annotated_img = detect_dogs_yolov5(img_path)\n",
        "\n",
        "    # Display the image with bounding boxes (if applicable)\n",
        "    if annotated_img is not None:\n",
        "        plt.imshow(cv2.cvtColor(annotated_img, cv2.COLOR_BGR2RGB))\n",
        "        plt.title('Detected Dogs with Bounding Boxes')\n",
        "        plt.show()\n",
        "\n",
        "    # If dogs detected, print their breeds\n",
        "    if dog_breeds:\n",
        "        for i, breed in enumerate(dog_breeds):\n",
        "            print(f\"Dog {i+1} breed: {breed}\")\n",
        "    else:\n",
        "        print(\"No dogs detected in the image.\")\n"
      ]
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
